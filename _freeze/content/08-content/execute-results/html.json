{
  "hash": "7fee66834a6bd23af8350e4b06ddbde2",
  "result": {
    "markdown": "---\ntitle: \"Causal Inference: Propensity Scores & Subgroup Analysis\"\ndate: \"2023-MAY-09\"\nexecute:\n  warning: false\n---\n\n\n\n\n## Downloads\n\nBelow is a link to the R script that will allow you to download the data and exercises. Copy the contents on your screen to a new R script, and run the script from the begging. Before class, it will be useful for you to:\n\n1.  Run \"source()\" file.\n2.  Last we you should have downloaded the synthetic data, and placed the dataset in a folder in your R project called \"data.\"\n3.  If you are stuck with this step, let us know.\n\n[link to script for this week](https://github.com/go-bayes/psych-434-2023/blob/main/scripts/workbook-8.R)\n\n## Overview\n\n### Goals\n\nBy the end of this lecture, you will understand the following concepts\n\n1.  Propensity-score weighting: modelling the exposure or treatment, not the outcome.\n2.  Doubly robust estimation: model both the treatment and the outcome.\n3.  Subgroup analysis by doubly-robust estimation.\n\n### Why is this important?\n\nRecall that in psychology our task is to answer some question about how people think and behave. In cross-cultural psychology these questions are typically comparative.\n\nOur first task is clearly define that question. Our second task is to answer that question.\n\nThe methods you will learn today will help you to define and answer comparative questions in psychology.\n\n## Review: The Fundamental Problem of Causal Inference as a Missing Data Problem\n\nRecall the fundamental problem of causal inference, returning to the question of whether bilingualism improves cognitive abilities:\n\n-   $Y_i^{a = 1}$: The cognitive ability of child $i$ if they were bilingual. This is the counterfactual outcome when A = 1.\n-   $Y_i^{a = 0}$:: The cognitive ability of child $i$ if they were monolingual. This is the counterfactual outcome when A = 0.\n\nThe causal effect of bilingualism on cognitive ability for individual $i$ is then defined as the difference between these potential outcomes:\n\n$$\n\\text{Causal Effect}_i = Y^{a=1} - Y^{a=0} \n$$\n\nWe say there is a causal effect if:\n\n$$\nY^{a=1} - Y^{a=0}  \\neq 0\n$$\n\nHowever, we only observe one of the potential outcomes for each child. The other outcome is not observed because physics prevents a child from both receiving and not receiving bilingual exposure.\n\nThe fact that causal contrasts are not observed on individuals is called \"The fundamental problem of causal inference.\"\n\nAlthough we typically cannot observe individual causal effects, under certain assumptions we can obtain average causal effects.\n\n\n```{=tex}\n\\begin{align}\nE(\\delta) = E(Y^{a=1} - Y^{a=0})\\\\\n          ~  = E(Y^{a=1}) - E(Y^{a=0}) \\\\\n          ~  = ATE\n\\end{align}\n```\n\nWe may identify average causal effects from the data when the following assumptions are met:\n\n-   Causal Consistency: The values of exposure under comparisons correspond to well-defined interventions that, in turn, correspond to the versions of treatment in the data.(see: Chatton, Hernan & Robbins)\n-   Positivity: The probability of receiving every value of the exposure within all strata of co-variates is greater than zero\n-   Exchangeablility: The conditional probability of receiving every value of an exposure level, though not decided by the investigators, depends only on the measured covariates (see: Chatton, Hernan & Robbins)\n\nFurther assumptions:\n\n-   No Interference: also known as the Stable Unit Treatment Value Assumption (SUTVA), requires that the treatment given to one unit (e.g., person, group, organization) does not interfere with the potential outcomes of another unit. Put differently, there are no \"spillover\" effects. Note: this assumption may be thought to be part of causal consistency, namely individual has only one potential outcome under each treatment condition.\n-   Correctly specified model: the requirement that the underlying statistical model used to estimate causal effects accurately represents the true relationships between the variables of interest. We say the model should be able to capture \"the functional form\" of the relationship between the treatment, the outcome, and any covariates. The functional form of the model should be flexible enough to capture the true underlying relationship. If the model's functional form is incorrect, the estimated causal effects may be biased. Additionally, the model must handle omitted variable bias by including all relevant confounders and should correctly handle missing data. We will return to the bias arising from missing data in the weeks ahead. For now, it is important to note that an assumption of causal inference is that our model is correctly specified.\n\n## Propensity Scores and Confounding Control\n\nRecall that last week, we considered confounding control by regression adjustment.\n\n$$\n\\begin{aligned}\nATE = E[Y^{a=1}|L = l] - E[Y^{a=0}|L = l] ~ \\text{for any value}~l\n\\end{aligned}\n$$\n\n> \"We say that a set L of measured non-descendants of L is a sufficient set for confounding adjustment when conditioning on L blocks all backdoor paths--that is, the treated and the untreated are exchangeable within levels of L\" (Hernan & Robins, What IF p. 86)\n\nThe equation you provided represents the average treatment effect (ATE) when conditioning on a set of covariates `L`:\n\n$$\n\\begin{aligned}\nATE = E[Y^{a=1}|L = l] - E[Y^{a=0}|L = l] ~ \\text{for any value}~l\n\\end{aligned}\n$$\n\nThis formula calculates the expected difference in outcomes between treated (a=1) and untreated (a=0) groups, given a specific value of the covariates `l`.\n\nNow, we will expand this explanation to include causal estimation by weighting of the covariates `L` on the exposure.\n\nOne common method for causal estimation by weighting is the inverse probability of treatment weighting (IPTW) using propensity scores. Propensity scores are the estimated probabilities of receiving the treatment given the covariates `L`. Denote the propensity score as $e(L) = P(a=1|L).$\n\nThis estimator involves two steps:\n\n1.  Estimate the propensity score e(L) using logistic regression or another appropriate method.\n\nThe weights are indeed calculated as follows:\n\nFor exposed individuals $(A_i = 1)$: The weight is the inverse of the propensity score, $\\frac{1} {e(L_i)}$. This means that exposed individuals with a lower probability of exposure (e.g., those with lower propensity scores) receive larger weights, increasing their influence on the comparison.\n\nFor unexposed individuals $(A_i = 0)$: The weight is the inverse of (1 - propensity score), $\\frac{1}{(1 - e(L_i))}$. This means that unexposed individuals with a higher probability of exposure (e.g., those with higher propensity scores) receive larger weights, also increasing their influence on the comparison.\n\n2.  Calculate the average treatment effect by weighting each individual's outcome by the inverse probability of receiving their observed treatment, given the covariates `L`.\n\nThe IPTW estimator for the average treatment effect can be defined as:\n\n$$\n\\begin{aligned}\nATE_{IPTW} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{A_i Y_i}{e(L_i)} - \\frac{1}{N} \\sum_{i=1}^{N} \\frac{(1 - A_i) Y_i}{1 - e(L_i)}\n\\end{aligned}\n$$\n\nwhere `N` is the number of observations, `a_i` is the treatment indicator for individual `i`, `Y_i` is the observed outcome for individual `i`, and `L_i` represents the covariates for individual `i`.\n\nThe IPTW estimator attempts to balance the distribution of the covariates `L` between treated and untreated groups by assigning weights based on the propensity scores. This approach aims to create a pseudo-population in which treatment assignment is independent of the covariates, allowing for an unbiased estimation of the average treatment effect, conditional on a correct specification of the model for the exposure.\n\n## Doubly Robust Estimation\n\nWe can combine regression based estimation and doubly robust estimation. I will walk you through the steps in today's exercises. The TL;DR is this: doubly robust estimation leads to lower reliance on correct model specification. If either the PS model or the regression model is correctly specified, the model will be unbiased -- if the other assumptions of causal inference are met.\n\nWe cannot know whether these assumptions are met, we will need to do sensitivity analysis, the topic of next week.\n\n## Subgroup analysis\n\nIn causal inference, these two concepts are related but have distinct meanings.\n\nLet $Y_{a}$ denote the counterfactual outcome Y when the experimental intervention $A$ is set to level $a$. Let $Y_{r}$ denote the counterfactual outcome $Y$ when another experimental intervention $R$ is set to level $r$. Following VanderWeele (2009), we can define interaction and effect modification as follows:\n\n1.  Interaction (causal interaction) on the difference scale, conditional on confounders $L$, occurs when:\n\n$$E(Y^{a1,r1}|L=l) - E(Y^{a0,r1}|L=l) \\neq E(Y^{a1,r0}|L=l) - E(Y^{a0,r0}|L=l)$$\n\nIn this case, we are considering a double intervention, and interaction occurs when the combined effect of interventions $A$ and $R$ is not equal to the sum of their individual effects.\n\n2.  Effect Modification (also known as \"heterogeneity of treatment effects\") occurs when the causal effect of intervention $A$ varies across different levels of another variable $R$:\n\n$$E(Y^{a=1}|R=r_1, L=l) - E(Y^{a=0}|R=r_1, L=l) \\neq E(Y^{a=1}|R=r_2, L=l) - E(Y^{a=0}|R=r_2, L=l)$$\n\nEffect modification indicates that the magnitude of the causal effect of intervention $A$ depends on the level of the modifier variable $R$. It is important to note that effect modification can be observed even when there is no direct causal interaction between the treatment and the modifier variable.\n\nIn short, interaction in causal inference refers to a situation where the combined effect of two interventions is not equal to the sum of their individual effects. Effect modification, on the other hand, occurs when the causal effect of one intervention varies across different levels of another variable.\n\nBy clearly distinguishing between these two concept, researchers can better ask, and answer, questions about human thinking and behaviour. For comparative research, we are typically interested in effect-modification which requires subgroup analysis.\n\nIn today's workbook, you will learn how to conduct doubly robust subgroup analysis.\n\n## Readings:\n\nNoah Griefer's Software and Blogs: [https://ngreifer.github.io/blog/subgroup-analysis-psm/](https://ngreifer.github.io/blog/)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}